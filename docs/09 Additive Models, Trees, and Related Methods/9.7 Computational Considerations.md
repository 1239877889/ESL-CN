# 计算的考虑

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-03-13                               |

在$N$个观测和$p$个预测变量的情形下，加性模型拟合需要$mp$个一维光滑器或回归方法的应用。backfitting算法的要求的圈数$m$通常小于20，并且经常小于10，而且取决于输入中的相关性大小。举个例子，三次光滑样条下，对于初始的排序需要$NlogN$次操作，以及对样条拟合的$N$操作。因此对于加性模型拟合总共的操作数为$pNlogN+mpN$.

对每个预测变量的初始排序，树需要$pNlogN$次操作，并且一般地对分割计算需要$pNlogN$次操作。如果分割在预测变量值域附近的边上，这个数目可能增大到$N^2p$.

MARS需要$Nm^2+pmN$次操作从$p$个预测变量中，往已经存在$m$项的模型中加入基函数。因此建立一个$M$项的模型需要$NM^3+pM^2N$次操作，如果$M$是 $N$中合理的一部分，则可能是相当禁止的。

HME的每一个组分在每个$M$步一般不需要花费太多来拟合：对于回归需要$Np^2$次，对于$K$个类别的逻辑斯蒂回归需要$Np^2K^2$次。然而，EM算法需要更长时间来收敛，因此较大的HME模型需要相当大的花费去拟合。

