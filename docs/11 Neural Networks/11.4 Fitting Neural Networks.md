# 拟合神经网络

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-02-07                               |
|更新|2017-12-27|

神经网络模型有未知的参数，通常称为权重，而且我们寻找它们的值使得模型很好地拟合训练数据。我们将参数的整个集合记为$\theta$，包括
$$
\begin{align}
\{\alpha_{0m},\alpha_m;m=1,2,\ldots,M\}\;&M(p+1)\text{个权重}\\
\{\beta_{0k},\beta_k;k=1,2,\ldots,K\}\;&K(M+1)\text{个权重}
\end{align}
\qquad (11.8)
$$
对于回归，我们采用误差平方和用于衡量拟合（误差函数）的效果
$$
R(\theta)=\sum\limits_{k=1}^K\sum\limits_{i=1}^N(y_{ik}-f_k(x_i))^2\qquad (11.9)
$$
对于分类，我们可以采用平方误差或者交叉熵（偏差）：
$$
R(\theta)=-\sum\limits_{i=1}^N\sum\limits_{k=1}^Ky_{ik}\mathrm{log}f_k(x_i)\qquad (11.10)
$$
以及对应的分类器$G(x)=\mathrm{arg\; max}_kf_k(x)$.有了softmax激活函数和交叉熵误差函数，神经网络模型实际上是关于隐藏层的线性逻辑斯蒂回归模型，而且所有的参数通过极大似然来估计。

一般地，我们不想要$R(\theta)$的全局最小值，因为可能会是一个过拟合解。而是需要一些正则化：这个可以通过惩罚项来直接实现，或者提前终止来间接实现。下一节中将给出详细的细节。

最小化$R(\theta)$的一般方法是通过梯度下降，在这种情形下称作向后传播。因为模型的组成成分，运用微分的链式法则可以很简单地得到梯度。这个可以通过对网络向前或向后遍历计算得到，仅跟踪每个单元的局部量。

下面是对于平方误差损失的向后传播的细节。由(11.5)式令$z_{mi}=\sigma(\alpha_{0m}+\alpha_m^Tx_i)$，并令$z_i=(z_{1i},z_{2i},\ldots,z_{Mi}).$则我们有
$$
\begin{align}
R(\theta)&\equiv\sum\limits_{i=1}^NR_i\\
&=\sum\limits_{i=1}^N\sum\limits_{k=1}^K(y_{ik}-f_k(x_i))^2\qquad (11.11)
\end{align}
$$
微分为
$$
\begin{align}
\frac{\partial R_i}{\partial \beta_{km}}&=-2(y_{ik}-f_k(x_i))g'_k(\beta_k^Tz_i)z_{mi}\\
\frac{\partial R_i}{\partial \alpha_{m\ell}}&=-\sum\limits_{k=1}^K2(y_{ik}-f_k(x_i))g'_k(\beta_k^Tz_i)\sigma'(\alpha_m^Tx_i)x_{i\ell}
\end{align}
\qquad (11.12)
$$
给定这些微分，梯度下降在第(r+1)步迭代更新为
$$
\begin{align}
\beta_{km}^{(r+1)}&=\beta_{km}^{(r)}-\gamma_r\sum\limits_{i=1}^N\frac{\partial R_i}{\partial \beta_{km}^{(r)}}\\
\alpha_{m\ell}^{(r+1)}&=\alpha_{m\ell}^{(r)}-\gamma_r\sum\limits_{i=1}^N\frac{\partial R_i}{\partial\alpha_{m\ell}^{(r)}}
\end{align}
\qquad (11.13)
$$
其中$\gamma_r$为学习速度，将在下面讨论。

现在将（11.12）式写成
$$
\begin{align}
\frac{\partial R_i}{\partial \beta_{km}}&=\delta_{ki}z_{mi}\\
\frac{\partial R_i}{\partial \alpha_{m\ell}}&=s_{mi}x_{i\ell}
\end{align}
\qquad (11.14)
$$
$\delta_{ki}$和$s_{mi}$的值分别为当前模型在输出和隐藏层单元的误差。从它们的定义来看，它们满足
$$
s_{mi}=\sigma'(\alpha_m^Tx_i)\sum\limits_{k=1}^K\beta_{km}\delta_{ki}\qquad (11.15)
$$
上式称为向后传播等式。用这个等式，（11.13）的更新可以通过双通（two-pass）算法来实现。在forward pass，固定当前权重，预测值$\hat f_k(x_i)$通过（11.5）式计算。在backward pass，计算当前误差$\delta_{ki}$，接着向后传播通过(11.15)式给出误差$s_{mi}$.则两个误差都用来计算（11.13）、（11.14）中更新的梯度。

这个two-pass过程称作向后传播。也被称为delta rule(Widrow and Hoff, 1960[^1])。交叉熵计算的组分与平方误差函数和有同样的形式，并且在练习11.3中被导出来。

向后传播的优点在于简单，局部自然。在向后传播算法中，每个隐藏层单元仅仅向（从）有其联系的单元传递（接收）信息。因此可以在并行架构的计算机上高效地实现。

（11.13）式的更新是一种batch learning，参数更新为所有训练情形的和。学习也可以online地进行——每次处理一个观测，每个训练情形过后更新梯度，然后对训练情形重复多次。在这种情形下，（11.13）式的和可以替换成单个被加数。训练时期（training epoch）指的是一次扫描整个训练集。在线（online）训练允许网络处理非常大的训练集，而且当新观测加入时更新权重。

batch learning的学习速率$\gamma_r$经常取为常数，而且可以通过在每次更新时运用线搜索最小化误差函数来优化。在线学习$\gamma_r$当$r\rightarrow \infty$时下降减为0.这个学习是随机近似（stochastic approximation）的形式（Robbins and Munro, 1951[^2]）;如果$\gamma_r\rightarrow \infty,\sum_r\gamma_r=\infty,$且$\sum_r\gamma_r^2<\infty$,（举个例子，$\gamma_r=1/r$便满足条件）则在这个领域内的结果保证收敛。

向后传播可以非常慢，而且因为这个原因经常不选择这个方法。像牛顿法的二阶技巧在这里不是很好，因为$R$的二阶微分矩阵（Hessian阵）可以变得非常大。更好的拟合方式包括共轭梯度法以及变量度量方法。它们避免直接计算二阶微分矩阵但仍然提供很快的收敛性。

[^1]: Widrow, B. and Hoff, M. (1960). Adaptive switching circuits, IRE WESCON Convention record, Vol. 4. pp 96-104; Reprinted in Andersen and Rosenfeld (1988).
[^2]: Robbins, H. and Munro, S. (1951). A stochastic approximation method, Annals of Mathematical Statistics 22: 400–407.
