# 模型选择和偏差-方差的权衡

原文     | [The Elements of Statistical Learning](../The Elements of Statistical Learning.pdf)
      ---|---
翻译     | szcf-weiya
时间     | 2016-08-01

上面讨论的所有模型以及其他将要在后面章节讨论的模型都有一个光滑或复杂性参数需要确定
- 惩罚项的乘子
- 核的宽度
- 基函数的个数

在光滑样条的情形下，参数$\lambda$为指标的模型从直线拟合到插值模型。类似地，局部阶为$m$的多项式模型从当观察的窗口无限大时阶为$m$的全局多项式到当观察的窗口收缩至零时的插值拟合。这意味着我们不能用训练数据的残差平方和来确定这些参数，因为我们总是选择插值拟合从而0残差。这样的一个模型不可能去预测未来的数据。

$k$-最近邻回归有效地拟合$\hat{f}_k(x_0)$说明了影响这些近似预测能力的竞争力。假设数据来自模型$Y=f(X)+\epsilon，E(\epsilon)=0,Var(\epsilon)=\sigma^2$。为了简化，我们假设样本中的值$x_i提前修正好（不是随机）$。在$x_0$处的预测误差期望，也被称为测试（*test*）或规范化(*generalization*)误差，可按如下方式分解：
$$
\begin{align}
EPE_k(x_0)&=E[(Y-\hat{f}_k(x_0))^2\mid X=x_0]\notag\\
&=\sigma^2+[Bias^2(\hat{f}_k(x_0))+Var_{\cal T}(\hat{f}_k(x_0))]\\
&=\sigma^2+[f(x_0)-\frac{1}{k}\sum\limits_{\ell=1}^kf(x_{(\ell)})]^2+\frac{\sigma^2}{k}
\end{align}
$$
带括号的下标$(\ell)$表示$x_0$的最近邻的顺序。

在展开式中有三项。第一项$\sigma^2$是不可约减的(*irreducible*)误差——是新测试目标点的方差——而且我们不能够控制，即使我们知道真值$f(x_0)$

第二项和第三项在我们的控制范围内，并且弥补了估计$f(x_0)$时$\hat{f}_k(x_0)$的均方误差(*mean squared error*)，均方误差经常被分解成偏差部分和方差部分。偏差项是真值均值$f(x_0)$与估计的期望值之间差异的平方——$[E_{\cal T}(\hat{f}_k(x_0))-f(x_0)]^2$——其中期望平均了训练数据中的随机量。如果真实的函数相当地光滑，这一项很可能随着$k$的增加而增加。对于较小的$k$值和较少的近邻点会导致值$f(x_{(\ell)})$与$f(x_0)$很接近，所以它们的平均应该距离$f(x_0)$很近。当$k$值增加，邻域远离，然后任何事情都可能发生。

这里的方差项是方差的简单平均，随着$k$变大会变小因为$k$的倒数关系。所以当$k$变化，会有偏差——误差的权衡(*bias-variance tradeoff*)

更一般地，随着我们过程的模型复杂度(*model complexity*)增加，方差趋于上升，偏差区域下降。当模型复杂度下降时会发生相反的行为。对于$k$-最近邻，模型复杂度由$k$来控制。

一般地，我们选择模型复杂度使偏差与方差达到均衡从而使测试误差最小。测试误差的显然的一个估计是训练误差(*training error*)$\frac{1}{N}\sum_i(y_i-\hat{y}_i)^2$。不幸的是，训练误差不是测试误差的良好估计，因为这个不是模型复杂度合适的说明。

![](../img/01/fig2.11.png)

图2.11：测试和训练错误随模型复杂度变化

图2.11显示了不同模型复杂度下测试和训练误差的典型表现。无论何时增加模型复杂度训练误差都趋于下降，这也就是，无论何时当我们拟合数据得更加困难。然而过度的拟合，模型会自适应使得更加接近训练数据，但不能很好的推广（比如说，有大的测试误差）。在预测值$\hat{f}(x_0)$有大方差的情形下，正如在式$\eqref{2.46}$最后一项显示的那样。相反的，如果模型不是特别的复杂，会拟合不足（*underfit*）且有大的偏差，再一次导致不能很好地推广。在第7章中，我们考虑估计预测方法测试误差的方法，并因此对于给定的预测方法和训练集估计最优的模型复杂度。
