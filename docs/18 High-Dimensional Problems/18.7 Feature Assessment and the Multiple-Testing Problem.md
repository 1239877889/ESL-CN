# 特征评估和多重检验问题

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-08-17:2017-08-19                    |

在本章的第一部分中我们讨论了$p>>N$情形下的预测模型。这里我们考虑在评估$p$个特征的显著性的这一基本问题。考虑18.4.1节中蛋白质质谱的例子。在这个问题中，研究者可能不关心对一个给定的病人作出预测，判断其是否有前列腺癌。而感兴趣的可能是识别出哪种蛋白质在正常群体和癌症群体中的含量有差异，由此加深对疾病的了解，并且对药物的研制有指导意义。因此我们的目标是评估单个特征的显著性。这个评估通常不用在本章中第一部分使用多变量预测模型来实现。特征评估问题将我们的关注点从预测移到传统的统计学话题——多重假设检验。在本章接下来的章节中，我们将用$M$来表示特征的个数，而不是$p$，因为我们将频繁用$p$表示$p$值。

![](../img/18/table18.4.png)

举个例子，考虑表18.4的微阵列数据，数据取自一项研究癌症患者对电离辐射治疗的敏感性的研究（Rieger等人，2004）。每一行包含58个病人样本的基因表达值：44个样本取自有正常反应的病人，而14个样本取自对电离辐射有严重反应的病人。测量值是在oligo-nucleotide微阵列上得到的。试验的目的是在对电离辐射敏感的病人群体中找出基因表达值不同的基因。总共有$M=12625$个基因，表中显示了部分基因和样本来解释。

为了识别出有用的基因，我们对每个基因构造两样本$t$统计量

$$
t_j = \frac{\bar x_{2j}-\bar x_{1j}}{se_j}\qquad (18.38)
$$

其中，$\bar x_{kj} = \sum_{i\in C_\ell}x_{ij}$。这里$C_\ell$是在群$\ell$中$N_\ell$个样本的指标集，其中$\ell = 1$表示正常的群体，而$\ell=2$表示敏感的群体。$se_j$是基因$j$的混合群内标准误差：

$$
se_j=\hat \sigma_j\sqrt{\frac{1}{N_1}+\frac{1}{N_2}}; \hat\sigma_j^2=\frac{1}{N_1+N_2-2}(\sum\limits_{i\in C_1}(x_{ij}-\bar x_{1j})^2+\sum\limits_{i\in C_2}(x_{ij}-\bar x_{2j})^2)
$$

![](../img/18/fig18.18.png)

图18.18的直方图用橘黄色显示了12625个t统计量，取值范围为-4.7到5.0。如果$t_j$服从正态分布，我们可以认为任何绝对值大于2的$t$统计量为显著的。这对应的显著水平为5%。这里有1189个基因的$\vert t_j\vert \ge 2$。然而，12625个基因中我们可能希望很多大的值是随机出现的，即使分组与任何基因都不相关。举个例子，如果基因是独立的（实际上它们当然不是），假阳性的基因个数会服从均值为$12625\cdot 0.05=631.3$，标准偏差为24.5的二项分布；实际的1189超出这个范围。

那我们怎么能够评估所有12625个基因的结果呢？这称为多重检验问题。我们可以像上面一样开始，计算每个基因的$p$值。当假设特征服从正态分布，这个可以使用理论上的$t$分布概率实现。一个吸引人的替代方案是使用排列分布，因为它避免了数据分布的假设。（理论上）我们计算样本的所有$K = \binom{58}{14}$种排列，并且对于每个排列$k$计算$t$统计量$t_j^k$。于是基因$j$的$p$值为

$$
p_j=\frac{1}{K}\sum\limits{k=1}^KI(\vert t_j^k\vert > \vert t_j\vert)\qquad (18.40)
$$

当然，$\binom{58}{14}$是很大的数（大约$10^{13}$），因此我们不能列举出所有可能的排列。相反地，我们取可能的排列的一个随机样本，这里我们取一个$K=1000$种排列的随机样本。为了利用基因都是相似的这一事实（比如，在同一尺度下测量），我们可以将所有基因混合一起计算$p$值

$$
p_j=\frac{1}{MK}\sum\limits_{j'=1}^M\sum\limits_{k=1}^KI(\vert t_{j'}^k\vert>\vert t_j\vert)\qquad (18.41)
$$

这也给出了比(18.40)式更细致的$p$值，因为在混合零分布中比单一的零分布使用了更多的值。

采用这个$p$值的集合，我们要检验下面的假设

$$
H_{0j} = \text{治疗对基因}j\text{无作用}\\
H_{1j} = \text{治疗对基因}j\text{有作用}\\
\text{for } j=1,2,\ldots, M
$$

如果$p_j<\alpha$，我们在$\alpha$的水平下拒绝$H_{0j}$。这个检验的第一类错误等于$\alpha$，也就是，错误拒绝$H_{0j}$的概率为$\alpha$.

现在考虑更多的检验，我们应该采用什么作为误差的整体衡量不是很明显。令$A_j$为$H_{0j}$被错误拒绝的事件，由定义知$Pr(A_j)=\alpha$。FWER是至少存在一个被错误拒绝的概率，并且经常用它作为整体错误的衡量。具体地，如果$A=\cup_{j=1}^MA_j$是至少有一个被错误拒绝的概率，于是FWER为$Pr(A)$。一般地，对于较大的$M$，$Pr(A)>>\alpha$，并且取决于检验之间的相关性。如果检验之间互相独立，且第一类错误概率为$\alpha$，则FWER为$(1-(1-\alpha)^M)$。另一方面，如果检验之间有正依赖，即$Pr(A_j\mid A_k)>Pr(A_j)$，则FWER会小于$(1-(1-\alpha)^M)$。测试直接的正依赖在实际中经常发生，特别是基因研究中。

做多重检验的一个很简单的方式是Bonferroni方法。它让每个个体检验更加严格，使得FWER至多等于$\alpha$: 如果$p_j<\alpha/M$， 我们拒绝$H_{0j}$。可以很简单地证明这会使得FWER$\le\alpha$。Bonferroni方法在$M$相对较小的情形下有用，但是对于大的$M$则太过保守，也就是，得到的显著基因数目过少。

在我们的例子中，如果在$\alpha=0.05$水平下检验，则我们需要采用的阈值为$0.05/12625=3.9\times 10^{-6}$。在12625个基因的$p$值中没有比这还小。

有许多对该方法的变形，通过调整单个$p$值使得FWER至多为$\alpha$，一些方法避免了对独立性的假设，比如，Dudoit等人（2002b）的工作。

## FDR
TODO

## 对称分割点和SAM过程
TODO

## FDR的贝叶斯解释
