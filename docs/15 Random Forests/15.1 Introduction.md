# 15.1 导言

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-01-28                               |

8.7节中的bagging或者bootstrap aggregation是为了降低估计的预测函数方差的技巧。bagging似乎对于高方差、低偏差的过程表现得特别好，比如树。对于回归， 我们简单地对训练数据的bootstrap版本的进行多次同样的回归树，然后取结果的平均。对于分类，树的每个committee对预测的类别进行投票。

第10章中的boosting一开始也是作为committee的方法提出来的，尽管不像bagging，weak learners的committee随着时间不断进化，并且成员投出带有权重的票。boosting似乎在大部分问题上占主导地位，而且因为偏好选择。

随机森林（Breiman，2011）是bagging的本质修改，而且建了一个de-correlated树的集合，然后进行平均。在许多问题上，随机森林的表现与报摄影的表现很相似，而且更加简单地进行训练和调参。结果，随机森林很流行，而且可以通过多种包来实现。