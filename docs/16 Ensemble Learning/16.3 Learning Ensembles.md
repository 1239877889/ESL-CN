# 学习集成

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-09-25                               |

前面章节的知识可以用来产生更高效的集成模型。我们继续考虑下面形式的函数

$$
f(x)=\alpha_0+\sum\limits_{T_k\in \cal T}\alpha_kT_k(x)\qquad (16.8)
$$

其中$\cal T$是基函数的字典，一般是树。对于gradient boosting和随机森林，$\vert\cal T\vert$非常大，而且一般最后的模型涉及上千棵树。

Friedman and Popescu (2003)提出混合的方式，它将这个过程分解为下面两步：

- 从训练集中导出有限的基函数字典集$\cal T_L=\{T_1(x), T_2(x),\ldots, T_M(x)\}$;
- 通过在字典集中拟合lasso路径来构造$f_\lambda(x)$函数族。
$$
\alpha(\lambda)=arg\;\underset{\alpha}{min}\sum\limits_{i=1}^NL[y_i, \alpha_0+\sum\limits_{m=1}^M\alpha_mT_m(x_i)]+\lambda\sum\limits_{m=1}^M\vert \alpha_m\vert\qquad (16.9)
$$

TODO
