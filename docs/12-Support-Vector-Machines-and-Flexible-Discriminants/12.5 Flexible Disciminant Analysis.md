# 12.5 FDA

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf#page=459) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-12-15                   |

在这一节我们描述一种在导出的响应变量上使用线性回归的 LDA 方法。这相应地导出非参的以及更灵活的替换 LDA 的方法。如第 4 章一样，我们假设我们有定量变量 $G$，它落入 $K$ 个类别 ${\cal G} = \{1,\ldots,K\}$ 中的其中一个类别，每个都有测量特征 $X$。假设 $\theta: \cal G\mapsto\IR^1$ 是对类别打分的函数，使得转换后的类别表情通过 $X$ 上的线性回归来最优预测：如果我们的训练样本形式为 $(g_i,x_i),i=1,2,\ldots,N$，则我们求解带关于$\theta$约束的下式来避免平凡解（在训练数据上均值为零单位方差）

$$
\underset{\beta,\theta}{\min}\sum\limits_{i=1}^N(\theta(g_i)-x_i^T\beta)^2\tag{12.52}
$$

这得到类别间的一维划分。

更一般地，我们可以寻找至多 $L\le K-1$ 个类别标签的独立得分， $\theta_1,\theta_2,\ldots,\theta_L$，并且 $L$ 个对应的线性映射 $\eta_\ell(X)=X^T\beta_\ell,\ell=1,\ldots,L$，它们的选择使得 $\IR^p$ 中的多重回归达到最优。得分 $\theta_\ell(g)$ 以及映射 $\beta_\ell$ 的选择使得均方残差最小

$$
ASR=\frac 1N\sum\limits_{\ell=1}^L[\sum\limits_{i=1}^N(\theta_\ell(g_i)-x_i^T\beta_\ell)^2]\tag{12.53}
$$

得分集假设为相互正交的并且关于合适的内积进行了标准化来避免平方的零解。