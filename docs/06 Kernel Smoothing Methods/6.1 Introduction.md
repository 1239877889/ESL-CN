# 6.1 导言

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-01-28                               |

这章中我们描述一类回归技巧，它是在定义域$R^p$中每个查询点$x_0$分别拟合不同但简单的模型对回归函数$f(X)$进行估计来实现灵活性。这个可以仅仅使用离目标点很近的观测点去拟合这个简单的模型办到，这种方式得到的估计函数$\hat f(X)$在$R^p$是光滑的。这个局部化可以通过一个加权的函数或者核函数$K_\lambda(x_0,x_i)$来实现，核函数是基于$x_i$到$x_0$的距离赋予一个权重。核$K_\lambda$一般地通过参数$\lambda$来编号，参数$\lambda$规定了邻域的宽度。这些基于基于记忆性的方法主要需要很少或者没有训练；所有的工作在评估时间便完成了。从训练集中唯一需要确定的参数是$\lambda$。然而，模型是整个训练数据集。

我们也讨论更加一般类别的基于核的技巧，它们与其他章节中结构化的方法联系在一起了，这在密度估计很分类中很有用。

本章中的技巧不应该与最近使用最多的“核方法”混淆。这章中，核大多作为局部化的工具。我们在5.8节，14.5.4节，18.5节和第12章讨论核方法；在这些部分，核在一个高维（隐式的）的特征空间中计算内积，而且被用于正规化非线性建模。我们将在本章的最后6.7节将这些方法联系起来。



