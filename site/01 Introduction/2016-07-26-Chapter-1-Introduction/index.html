<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://szcf-weiya.github.io/ESL-CN/01 Introduction/2016-07-26-Chapter-1-Introduction/">
        <link rel="shortcut icon" href="../../img/favicon.ico">

	<title>1.1 导言 - ESL CN</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/newsprint.css" rel="stylesheet">
        <link href="../../css/admonition_fix.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-85046550-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="../..">ESL CN</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
                <li >
                    <a href="../..">主页</a>
                </li>
            
            
            
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">目录 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">序言</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../Preface/2016-07-20-Preface-to-the-Second-Edition/">第二版序言</a>
</li>

        
            
<li >
    <a href="../../Preface/2016-07-21-Preface-to-the-First-Edition/">第一版序言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">1 简介</a>
    <ul class="dropdown-menu">
        
            
<li class="active">
    <a href="./">1.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">2 监督学习概要</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.1 Introduction/">2.1 导言</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.2 Variable Types and Terminology/">2.2 变量类型和术语</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.3 Two Simple Approaches to Prediction/">2.3 两种预测的简单方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.4 Statistical Decision Theory/">2.4 统计判别理论</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.5 Local Methods in High Dimensions/">2.5 高维问题的局部方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.6 Statistical Models, Supervised Learning and Function Approximation/">2.6 统计模型，监督学习和函数逼近</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.7 Structured Regression Models/">2.7 结构化的回归模型</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.8 Classes of Restricted Estimators/">2.8 限制性估计的类别</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.9 Model Selection and the Bias-Variance Tradeoff/">2.9 模型选择和偏差-方差的权衡</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">3 回归的线性方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.1 Introduction/">3.1 导言</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.2 Linear Regression Models and Least Squares/">3.2 线性回归模型和最小二乘法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.3 Subset Selection/">3.3 子集的选择</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.4 Shrinkage Methods/">3.4 收缩的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.5 Methods Using Derived Input Directions/">3.5 运用派生输入方向的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.6 A Comparison of the Selection and Shrinkage Methods/">3.6 选择和收缩方法的比较</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.7 Multiple Outcome Shrinkage and Selection/">3.7 多重输出的收缩和选择</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">4 分类的线性方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.1 Introduction/">4.1 导言</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.2 Linear Regression of an Indicator Matrix/">4.2 指示矩阵的线性回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.3 Linear Discriminant Analysis/">4.3 线性判别分析</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.4 Logistic Regression/">4.4 逻辑斯蒂回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.5 Separating Hyperplanes/">4.5 分离超平面</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">5 基展开和正规化</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../05 Basis Expansions and Regularization/5.1 Introduction/">5.1 导言</a>
</li>

        
            
<li >
    <a href="../../05 Basis Expansions and Regularization/5.2 Piecewise Polynomials and Splines/">5.2 分段多项式和样条</a>
</li>

        
            
<li >
    <a href="../../05 Basis Expansions and Regularization/5.3 Filtering and Feature Extraction/">5.3 滤波和特征提取</a>
</li>

        
            
<li >
    <a href="../../05 Basis Expansions and Regularization/5.4 Smoothing Splines/">5.4 光滑样条</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">6 核光滑方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.1 Introduction/">6.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">7 模型评估及选择</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.1 Introduction/">7.1 导言</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.2 Bias, Variance and Model Complexity/">7.2 偏差，方差和模型复杂度</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.3 The Bias-Variance Decomposition/">7.3 偏差-方差分解</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.10 Cross-Validation/">7.10 交叉验证</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">8 模型推断和平均</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.1 Introduction/">8.1 导言</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.2 The Bootstrap and Maximum Likelihood Methods/">8.2 自助法和最大似然法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.3 Bayesian Methods/">8.3 贝叶斯方法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.4 Relationship Between the Bootstrap and Bayesian Inference/">8.4 自助法和贝叶斯推断之间的关系</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.5 The EM Algorithm/">8.5 EM算法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.6 MCMC for Sampling from the Posterior/">8.6 MCMC向后采样</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.7 Bagging/">8.7 袋装法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">9 增广模型，树，以及相关方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.0 Introduction/">9.0 导言</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.1 Generalized Additive Models/">9.1 广义加性模型</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.2 Tree-Based Methods/">9.2 基于树的方法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">10 增强和加性树</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.1 Boosting Methods/">10.1 增强方法</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.2 Boosting Fits an Additive Model/">10.2 对加性模型的增强拟合</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.3 Forward Stagewise Additive Modeling/">10.3 向前逐步加性建模</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.4 Exponential Loss and AdaBoost/">10.4 指数损失和AdaBoost</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.5 Why Exponential Loss/">10.5 为什么是指数损失</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.6 Loss Functions and Robustness/">10.6 损失函数和鲁棒性</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">11 神经网络</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../11 Neural Networks/11.1 Introduction/">11.1 导言</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.2 Projection Pursuit Regression/">11.2 投影寻踪回归</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.3 Neural Networks/">11.3 神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.4 Fitting Neural Networks/">11.4 拟合神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.5 Some Issues in Training Neural Networks/">11.5 训练神经网络的一些问题</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.6 Example of Simulated Data/">11.6 模拟数据的例子</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">12 支持向量机和灵活的判别方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.1 Introduction/">12.1 导言</a>
</li>

        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.2 The Support Vector Classifier/">12.2 支持向量分类器</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">13 原型方法和最近邻</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.1 Introduction/">13.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">15 随机森林</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../15 Random Forests/15.1 Introduction/">15.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                    </ul>
                </li>
            
            
            </ul>

            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> 搜索
                    </a>
                </li>
                <li >
                    <a rel="next" href="../../Preface/2016-07-21-Preface-to-the-First-Edition/">
                        <i class="fa fa-arrow-left"></i> 上一节
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../../02 Overview of Supervised Learning/2.1 Introduction/">
                        下一节 <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                <li>
                    <a href="https://szcf-weiya.github.io">
                        
                        Szcf-Weiya
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#_1">导言</a></li>
        
            <li><a href="#1">例1：垃圾电子邮件</a></li>
        
            <li><a href="#2">例2：前列腺癌</a></li>
        
            <li><a href="#3">例3：手写数字识别</a></li>
        
            <li><a href="#4">例4：基因表达微阵列</a></li>
        
            <li><a href="#_2">谁应该读读这本书</a></li>
        
            <li><a href="#_3">这本书是如何组织的</a></li>
        
            <li><a href="#_4">书的网址</a></li>
        
            <li><a href="#_5">教师注意事项</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="_1">导言</h1>
<table>
<thead>
<tr>
<th>原文</th>
<th><a href="../../The Elements of Statistical Learning.pdf">The Elements of Statistical Learning</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>翻译</td>
<td>szcf-weiya</td>
</tr>
<tr>
<td>时间</td>
<td>2016-07-26</td>
</tr>
</tbody>
</table>
<p>统计学习在科学、经济和工业的许多领域都扮演着重要角色。下面是学习问题中的一些例子。</p>
<ul>
<li>
<p>预测一个心脏病患者是否会发生第二次心脏病。这些预测是基于人口统计学，该患者的饮食和临床表现。</p>
</li>
<li>
<p>基于公司的表现和经济数据来预测从现在起六个月后股票的价格。</p>
</li>
<li>
<p>从数字化图像中确定手写的邮政编码中的数字</p>
</li>
<li>
<p>从糖尿病患者血液中的红外光谱吸收情况来估计该患者血液中的葡萄糖含量。</p>
</li>
<li>
<p>基于临床和人口统计学变量确定前列腺癌的致病因素</p>
</li>
<li>
<p>在统计、数据挖掘和人工智能等领域学习扮演了重要角色，与工程和其他学科都有交叉。</p>
</li>
<li>
<p>这本书关于从数据中学习。在一个典型的情境中，我们有一个希望能够基于一系列特征（如饮食和临床表现）预测的结果，通常是数量（如股票价格）或者类别（比如有心脏病和没有心脏病）。我们有一系列训练数据，其中有我们对结果的观测数据和对一系列物体（如人类）的特征测量。利用这些数据我们建立预测模型，或者学习，这个模型或学习能够让我们预测新的未知的物体的结果。一个好的学习是能够准确预测出一个结果。</p>
</li>
</ul>
<p><img alt="" src="../../img/01/intro_1.png" /></p>
<p><strong>表1.1：</strong>电子邮件信息中的指示字符等于字符的平均比例。我们选择垃圾邮件和电子邮件，表1.1显示了两者的巨大区别。</p>
<p>上述的例子描述的是监督学习问题。之所以称之为监督学习是因为存在结果变量来引导学习的过程。在非监督学习中，我们仅仅观察特征而且没有对结果的测量。我们的任务而是描述数据是如何形成的或者成簇的。我们将本书的绝大部分致力于监督学习，非监督学习问题的进展也相对较小，我们将在最后一章讨论。</p>
<p>下面是在本书中讨论的一些真实的学习问题。</p>
<h2 id="1">例1：垃圾电子邮件</h2>
<p>例子中的数据包含4601封电子邮件的信息，在一项研究中试图预测一封电子邮件是否是垃圾邮件。目标是涉及一个自动垃圾邮件检测器，该检测器可以在邮件塞进用户邮箱前过滤掉垃圾电子邮件。对于所有的4601封电子邮件，可用的真实结果是邮件或者垃圾邮件，同时还有57个常用词和标点符号的相对频率。这是一个监督学习的例子，其中结果变量是类别型变量 <strong>email/spam</strong>。这也被称作分类问题。</p>
<p>表1.1列出了垃圾邮件和普通邮件平均差异比较大的单词和字符。</p>
<p>我们的学习方法要决定用哪个特征以及怎么使用，比如说，我们会有下述规则</p>
<p><strong>当(%george &lt; 0.6) 且 (%you &gt; 1.5)时，为垃圾邮件，否则为普通邮件</strong></p>
<p>另一条规则可能是</p>
<p><strong>当(0.2 · %you − 0.3 · %george) &gt; 0时，为垃圾邮件，否则为普通邮件</strong></p>
<p>对于这个问题不是所有的错误都相等，我们想要避免过滤掉好的电子邮件，尽管让垃圾邮件通过不是想要的但是结果不是很严重。我们将在本书中讨论一系列不同的方法来解决这个学习问题。</p>
<h2 id="2">例2：前列腺癌</h2>
<p><img alt="" src="../../img/01/fig1.1.png" /></p>
<p>图1.1是前列腺癌数据的散点图矩阵。第一行显示了响应变量和自变量之间的关系。其中两个自变量，<em>svi</em>和<em>gleason</em>是类别型变量。</p>
<p>这个例子的数据如图1.1所示，来自1989年Stamey和其他人的检验前列腺癌特定抗原水平和临床措施之间相关性的研究，其中有97名男性接受了彻底的前列腺切除术。</p>
<p>目标是根据癌体积的对数值（<em>lcavol</em>）、前列腺重量的对数值（<em>lweight</em>）、良性前列腺增生数量（<em>lbph</em>）、精囊浸润（<em>svi</em>）、包膜浸透的对数值（<em>lcp</em>）、Gleason得分（<em>gleason</em>）、Gleason得分为4或5的比例（<em>pgg45</em>）来预测PSA的对数值（<em>lpsa</em>）。图1.1是这些变量的散点图矩阵。一些和（<em>lpsa</em>）的值是显著的，但是一个好的预测模型是很难根据眼睛构造出来的。</p>
<p>这是一个监督学习的问题，也称之为回归问题，因为结果测量是可量化的。</p>
<h2 id="3">例3：手写数字识别</h2>
<p><img alt="" src="../../img/01/fig1.2.png" /></p>
<p>本例的数据是来自美国邮局中信封上的手写邮政编码。每张图片是五位邮政编码的一部分，并且每个数字分隔开了。这些图片是16*16的8位灰度位图，每个像素点密度值为0到255.一些样例图片如图1.2所示。</p>
<p>这些图片都已经被标准化为几乎同样尺寸同样方向的图片了。任务是从16*16的灰度值矩阵中快速用准确的判断每张图片上的数字（0，1，&hellip;，9）。如果结果够精确，最终的算法会用到自动整理信封的过程中。这是一个分类问题，而且要求犯错误概率要很低避免分错邮箱。为了实现低错误率，一些物品要被分到不知道这个类里面，然而人工分拣。</p>
<h2 id="4">例4：基因表达微阵列</h2>
<p>DNA是脱氧核糖核酸，而且是组成人类染色体的基本材料。DNA表达微阵列通过测量一个细胞某基因的mRNA的量来衡量基因的表达情况。DNA表达微阵列被当作一个生物学领域的重大突破，促进了对单个细胞内成千上万基因同时量化研究。</p>
<p>下面介绍DNA表达微阵列如何工作。几千个基因的核苷酸序列打印在载玻片上。分别用红色和绿色染料标记目标样本和参照样本，并且每个都与载玻片上的DNA混合。通过X光透视检查，可以测量出每个位置上红色/绿色的RNA强度之比的对数值。结果是几千个数，基本上在-6到6之间，衡量每个目标样本中基因相对于参考样本中基因的表达水平。正值表示目标样本中基因表达程度更高，反之亦然。</p>
<p>一个基因表达数据集收集了一系列DNA微阵列实验中的表达的值，每一列表示一次实验。因此几千行表示几千个不同的基因，每一列表示一个样本：在图1.3中有6830个基因（行）和64个样本（列），尽管为了清晰只有一个随机样本的100行显示出来。这张图是用热点图显示了该数据集，从绿色（消极）到红色（积极）。样本是从不同病人得到的64个癌症肿瘤。</p>
<p>这里的挑战是理解基因和样本是怎样组织起来的。典型的问题有如下几个：</p>
<p>(a) 根据基因的表达谱，哪些样本两两之间最相似？</p>
<p>(b) 根据样本的表达谱，哪些基因两两之间最相似？</p>
<p>(C) 对于特定的癌症样本，特定的基因是否有非常高或低的表达？</p>
<p>我们可以把这个任务看成是回归问题，有两个类别型自变量——基因和样本——以及对应变量的表达水平。然而，把这个问题看成是非监督学习可能更有用。例如，对于上述的问题(a)，我们把样本看成是6830维空间中的一点，并且想通过某种方式对其进行聚类。</p>
<p><img alt="" src="../../img/01/fig1.3.png" /></p>
<p>图1.3 DNA阵列数据：基于人类肿瘤数据的6830个基因（行）、64个样本（列）的基因表达矩阵。只有随机的100行显示在图中。使用热点图描述这些数据，从绿色（消极，抑制表达）到红色（积极，过表达）。缺失数据为灰色。行和列是采用随机的顺序展示。</p>
<h2 id="_2">谁应该读读这本书</h2>
<p>这本书是为了许多领域的研究者和学生设计的，这些领域包括统计、人工智能、工程、金融以及其他。我们预期读者至少学过统计的一门基础课程，掌握包括线性回归等基本概念。</p>
<p>我们没有试图写一篇全面的关于学习方法的目录，而是描述一些很重要的技巧。同样值得说明的是，我们描述根本的概念和用于研究者评判学习方法需要考虑的因素。我们试图从一个直观的角度来写这本书，强调概念而不是数学细节。</p>
<p>作为统计学家，我们的描述自然反映了我们的背景和专业领域。然而在过去八年时间里我们参加了神经网络、数据挖掘和机器学习领域的会议，而且我们的想法已经深深被这些令人激动的领域所影响，这些影响在我们当前研究以及这本书中是很明显的。</p>
<h2 id="_3">这本书是如何组织的</h2>
<p>我们的观点是一个人在尝试掌握复杂的概念前必须理解简单的方法。因此，当在<strong>第二章</strong>对监督学习给出概要后，我们在<strong>第三和第四章</strong>讨论了回归和分类的线性方法。<strong>第五章</strong>我们描述了对单个自变量的样条，小波和正则/惩罚方法，<strong>第六章</strong>则描述了核方法和局部回归。上述两种方法都是高纬学习技术的重要基石。模型评估与选择是<strong>第七章</strong>的主题，包括偏差和方差，过拟合和用于选择模型用的交叉验证。<strong>第八章</strong>讨论了模型推断与平均，概要地介绍了极大似然法、贝叶斯推断、自助法、EM算法、吉布斯抽样和bagging。与此相关的boosting过程是<strong>第十章</strong>的重点。</p>
<p>在<strong>第九到十三章</strong>我们描述了一系列用于监督学习的结构化方法，其中<strong>第九和第十一章</strong>介绍回归以及<strong>第十二和第十三章</strong>重点在分类。<strong>第十四章</strong>描述了非监督学习的方法。两个最近提出来的技术，随机森林和集成学习将在<strong>第十五和第十六章</strong>讨论。我们在<strong>第十七章</strong>讨论无向图模型以及最后在<strong>第十八章</strong>学习高纬问题。</p>
<p>在每一张结尾我们讨论计算需要考虑的因素，这对於数据挖掘的应用是很重要的，包括计算量级随着观测值和自变量数目的变化。每一章节最后的文献注解提供了本章的背景参考资料。</p>
<p>我们建议按顺序先阅读第1-4章，第7章也应该当作强制阅读，因为它介绍了关于所有学习方法的中心概念。有了这些概念，这本书的其他章节根据读者的兴趣可以按照顺序读，或选读。</p>
<p>这个标志表明这是技术上困难的部分，读者可以跳过这部分而且不会影响后续讨论。</p>
<h2 id="_4">书的网址</h2>
<p>这本书的网站是
<a href="http://www-stat.stanford.edu/ElemStatLearn">http://www-stat.stanford.edu/ElemStatLearn</a>
里面包含很多资源，包括这本书里面用到的很多数据集。</p>
<h2 id="_5">教师注意事项</h2>
<p>我们成功地将这本书的第一版用做两个短学期的课程基础，如果加上第二版中的补充材料，可以用做三个短学期。练习题在每一章的最后。对学生而言，使用良好的软件处理书后的问题是很重要的。我们在自己的教学课堂上使用R和S-PLUS 编程。</p>

<div id="disqus_thread"></div>
<script>

/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
/*
var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//weiya.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<script id="dsq-count-scr" src="//weiya.disqus.com/count.js" async></script></div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <center>Powered by <a href="http://www.mkdocs.org/">MkDocs</a> and <a href="http://bootswatch.com/yeti/">Yeti</a></center>
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>var base_url = '../..';</script>
        <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
        <script src="../../js/base.js"></script>
        <script src="../../js/MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
        <script src="../../js/mymathjax.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">关闭</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">搜索</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            请在下面输入你要搜索的文本（仅支持英文）：
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="搜索..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>