<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://szcf-weiya.github.io/ESL-CN/08 Model Inference and Averaging/8.3 Bayesian Methods/">
        <link rel="shortcut icon" href="../../img/favicon.ico">

	<title>8.3 贝叶斯方法 - ESL CN</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/newsprint.css" rel="stylesheet">
        <link href="../../css/admonition_fix.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-85046550-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="../..">ESL CN</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
                <li >
                    <a href="../..">主页</a>
                </li>
            
            
            
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">目录 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">序言</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../Preface/2016-07-20-Preface-to-the-Second-Edition/">第二版序言</a>
</li>

        
            
<li >
    <a href="../../Preface/2016-07-21-Preface-to-the-First-Edition/">第一版序言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">1 简介</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../01 Introduction/2016-07-26-Chapter-1-Introduction/">1.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">2 监督学习概要</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.1 Introduction/">2.1 导言</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.2 Variable Types and Terminology/">2.2 变量类型和术语</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.3 Two Simple Approaches to Prediction/">2.3 两种预测的简单方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.4 Statistical Decision Theory/">2.4 统计判别理论</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.5 Local Methods in High Dimensions/">2.5 高维问题的局部方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.6 Statistical Models, Supervised Learning and Function Approximation/">2.6 统计模型，监督学习和函数逼近</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.7 Structured Regression Models/">2.7 结构化的回归模型</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.8 Classes of Restricted Estimators/">2.8 限制性估计的类别</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.9 Model Selection and the Bias-Variance Tradeoff/">2.9 模型选择和偏差-方差的权衡</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">3 回归的线性方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.1 Introduction/">3.1 导言</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.2 Linear Regression Models and Least Squares/">3.2 线性回归模型和最小二乘法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.3 Subset Selection/">3.3 子集的选择</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.4 Shrinkage Methods/">3.4 收缩的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.5 Methods Using Derived Input Directions/">3.5 运用派生输入方向的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.6 A Comparison of the Selection and Shrinkage Methods/">3.6 选择和收缩方法的比较</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.7 Multiple Outcome Shrinkage and Selection/">3.7 多重输出的收缩和选择</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">4 分类的线性方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.1 Introduction/">4.1 导言</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.2 Linear Regression of an Indicator Matrix/">4.2 指示矩阵的线性回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.3 Linear Discriminant Analysis/">4.3 线性判别分析</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.4 Logistic Regression/">4.4 逻辑斯蒂回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.5 Separating Hyperplanes/">4.5 分离超平面</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">5 基展开和正规化</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../05 Basis Expansions and Regularization/5.1 Introduction/">5.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">6 核光滑方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.1 Introduction/">6.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">7 模型评估及选择</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.1 Introduction/">7.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">8 模型推断和平均</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../8.1 Introduction/">8.1 导言</a>
</li>

        
            
<li >
    <a href="../8.2 The Bootstrap and Maximum Likelihood Methods/">8.2 自助法和最大似然法</a>
</li>

        
            
<li class="active">
    <a href="./">8.3 贝叶斯方法</a>
</li>

        
            
<li >
    <a href="../8.4 Relationship Between the Bootstrap and Bayesian Inference/">8.4 自助法和贝叶斯推断之间的关系</a>
</li>

        
            
<li >
    <a href="../8.5 The EM Algorithm/">8.5 EM算法</a>
</li>

        
            
<li >
    <a href="../8.6 MCMC for Sampling from the Posterior/">8.6 MCMC向后采样</a>
</li>

        
            
<li >
    <a href="../8.7 Bagging/">8.7 袋装法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">9 增广模型，树，以及相关方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.0 Introduction/">9.0 导言</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.1 Generalized Additive Models/">9.1 广义加性模型</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.2 Tree-Based Methods/">9.2 基于树的方法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">10 增强和加性树</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.1 Boosting Methods/">10.1 增强方法</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.2 Boosting Fits an Additive Model/">10.2 对加性模型的增强拟合</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.3 Forward Stagewise Additive Modeling/">10.3 向前逐步加性建模</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.4 Exponential Loss and AdaBoost/">10.4 指数损失和AdaBoost</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.5 Why Exponential Loss/">10.5 为什么是指数损失</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.6 Loss Functions and Robustness/">10.6 损失函数和鲁棒性</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">11 神经网络</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../11 Neural Networks/11.1 Introduction/">11.1 导言</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.2 Projection Pursuit Regression/">11.2 投影寻踪回归</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.3 Neural Networks/">11.3 神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.4 Fitting Neural Networks/">11.4 拟合神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.5 Some Issues in Training Neural Networks/">11.5 训练神经网络的一些问题</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.6 Example of Simulated Data/">11.6 模拟数据的例子</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">12 支持向量机和灵活的判别方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.1 Introduction/">12.1 导言</a>
</li>

        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.2 The Support Vector Classifier/">12.2 支持向量分类器</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">13 原型方法和最近邻</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.1 Introduction/">13.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">15 随机森林</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../15 Random Forests/15.1 Introduction/">15.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                    </ul>
                </li>
            
            
            </ul>

            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> 搜索
                    </a>
                </li>
                <li >
                    <a rel="next" href="../8.2 The Bootstrap and Maximum Likelihood Methods/">
                        <i class="fa fa-arrow-left"></i> 上一节
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../8.4 Relationship Between the Bootstrap and Bayesian Inference/">
                        下一节 <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                <li>
                    <a href="https://szcf-weiya.github.io">
                        
                        Szcf-Weiya
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#_1">贝叶斯方法</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="_1">贝叶斯方法</h1>
<table>
<thead>
<tr>
<th>原文</th>
<th><a href="../../book/The Elements of Statistical Learning.pdf">The Elements of Statistical Learning</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>翻译</td>
<td>szcf-weiya</td>
</tr>
<tr>
<td>时间</td>
<td>2017-02-01</td>
</tr>
</tbody>
</table>
<p>在贝叶斯推断中，在给出参数的情况下对于我们的数据确定样本模型$Pr(\mathbf Z;\theta)$(密度或者概率质量函数)，以及反映我们在得到数据之前对于$\theta$的认知的$Pr(\theta)$的先验分布。然后我们计算后验分布
<script type="math/tex; mode=display">
Pr(\theta;\mathbf Z)=\frac{Pr(\mathbf Z\mid\theta)\cdot Pr(\theta)}{\int Pr(\mathbf Z\mid \theta)\cdot Pr(\theta)d\theta}\qquad (8.23)
</script>
</p>
<p>它表示当我们知道数据后更新对$\theta$的认知。为了理解这一后验分布，可以从中抽取样本或者通过计算均值或众数来概况它。贝叶斯方法不同于一般的推断方法在于在知道数据之前用先验分布来表达这种不确定性，而且在知道数据之后运行不确定性继续存在，表示成后验分布。</p>
<p>后验分布也提供了预测未来观测$z^{new}$值的基，通过预测分布：
<script type="math/tex; mode=display">
Pr(z^{new}\mid \mathbf  Z)=\int Pr(z^{new}\mid \theta)\cdot Pr(\theta\mid \mathbf Z)d\theta\qquad (8.24)
</script>
相反地，最大似然方法会使用在最大概率估计那个点的密度$Pr(z^{new}\mid \hat\theta)$来预测未来的数据。不同于（8.24）的预测分布，这个并不说明估计$\theta$的不确定性。</p>
<p>让我们在光滑化例子中采用贝叶斯方法。首先从由(8.5)式给出的参数模型开始，然后假设$\sigma^2$是已知的。我们假设观测特征的值为$x_1,x_2,\ldots,x_N$是固定的，因此数据的随机性仅仅来源于$y$与均值$\mu(x)$的偏差。</p>
<p>第二步我们需要先验分布。函数的分布是相当复杂的：一种方式是使用先验高斯过程，其中我们指定任何两个函数值$\mu(x)$和$\mu(x&rsquo;)$的先验协方差。（Wahba,1990; Neal, 1996）</p>
<p>这里我们采取一个简单的方法：考虑$\mu(x)$的有限$B$样条基，则可以得到系数$\beta$的先验分布，而且这隐式地定义了$\mu(x)$的先验分布。我们选取中心化的先验高斯分布
<script type="math/tex; mode=display">
\beta\sim N(0,\tau\mathbf \Sigma)\qquad (8.25)
</script>
先验协方差矩阵$\mathbf \Sigma$和方差$\tau$将在下面讨论。$\mu(x)$的隐式先验过程因此是高斯的，因为协方差核
<script type="math/tex; mode=display">
\begin{align}
K(x,x')&= cov[\mu(x),\mu(x')]\\
&=\tau\cdot h(x)^T\mathbf\Sigma h(x')\qquad (8.26)
\end{align}
</script>
$\beta$的后验分布也是高斯的，均值和方差分别为
<script type="math/tex; mode=display">
\begin{align}
E(\beta\mid \mathbf Z)&=(\mathbf{H^TH}+\frac{\sigma^2}{\tau}\mathbf\Sigma^{-1})^{-1}\mathbf{H^Ty}\\
Cov(\beta\mid\mathbf Z)&=(\mathbf{H^TH}+\frac{\sigma^2}{\tau}\mathbf \Sigma^{-1})^{-1}\sigma^2
\end{align}
\qquad (8.27)\qquad (???????)
</script>
后验$\mu(x)$对应的相应值为
<script type="math/tex; mode=display">
\begin{align}
E(\mu(x)\mid\mathbf Z)&=h(x)^T(\mathbf{H^TH}+\frac{\sigma^2}{\tau}\mathbf\Sigma^{-1})^{-1}\mathbf{H^Ty}\\
cov[\mu(x),\mu(x')\mid\mathbf Z]&=h(x)^T(\mathbf{H^TH}+\frac{\sigma^2}{\tau}\mathbf\Sigma^{-1})^{-1}\sigma^2
\end{align}
\qquad (8.28)
</script>
我们怎样选取先验协方差矩阵$\mathbf \Sigma$?在某些设定下先验可以从对参数的主观感受来选择。这里我们愿意说函数$\mu(x)$应该为光滑的，而且已经通过将$\mu$表示成低纬度的B-样条的基来保证。因此我们可以选取先验协方差阵为单位阵$\mathbf {\Sigma=I}$.当基函数的个数很多，这或许不是充分的，通过对$\mathbf\Sigma$上加限制条件来保证额外的光滑；这恰巧是光滑样条的情形（5.8.1节）</p>
<p><img alt="" src="../../img/08/fig8.3.png" /></p>
<blockquote>
<p>图8.3. 光滑例子：十条函数$\mu(x)$高斯先验分布的曲线。</p>
</blockquote>
<p>图8.3显示了10个$\mu(x)$对应的先验。为了产生函数$\mu(x)$后验的值，我们从后验（8.27）式得到$\beta&rsquo;$，给出对应后验的值$\mu&rsquo;(x)=\sum_1^7\beta_j&rsquo;h_j(x)$.十条这样的后验曲线如图8.4所示。取了两个不同的先验方差$\tau$的值，1和1000.注意到右图与p263的图8.2的左下图的相似度。这种相似性不是偶然的。当$\tau\longrightarrow \infty$,后验分布（8.27）和自助法分布（8.7）相同。另一方面，对于$\tau=1$,图8.4左图的后验曲线$\mu(x)$比自助法曲线更加光滑，因为我们在光滑性上面强加了更多先验权重。</p>
<p><img alt="" src="../../img/08/fig8.4.png" /></p>
<blockquote>
<p>图8.4. 光滑例子：对于两个不同的先验方差$\tau$,十条函数$\mu(x)$后验分布的曲线。紫色的曲线是后验均值。</p>
</blockquote>
<p>当$\tau\longrightarrow \infty$时的分布（8.25）称为$\theta$的无信息先验（noninformative prior），在高斯模型中，极大似然和参数自助法趋向于与对自由参数使用无信息先验的贝叶斯分析一致。这些趋向于一致，因为在常值先验情况下，后验分布与概率成比例。这种对应也可以推广到非参的情形。其中非参自助法近似于一个无信息先验的贝叶斯分析；8.4节将详细介绍细节。</p>
<p>然而，我们已经做了一些从贝叶斯观点来看不是很恰当的事情。我们已经用了$\sigma^2$的无信息（常值）先验，而且在后验中换成了最大似然估计$\hat\sigma^2$。一个更加标准的贝叶斯分析也会在$\sigma$上加先验（一般地，$g(\sigma)\propto 1/\sigma$）,计算$\mu(x)$和$\sigma$的联合后验分布，然后把$\sigma$整合出来，而不是仅仅提取后验分布的最大值（“MAP”估计）</p>

<div id="disqus_thread"></div>
<script>

/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
/*
var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//weiya.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<script id="dsq-count-scr" src="//weiya.disqus.com/count.js" async></script></div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <center>Powered by <a href="http://www.mkdocs.org/">MkDocs</a> and <a href="http://bootswatch.com/yeti/">Yeti</a></center>
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>var base_url = '../..';</script>
        <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
        <script src="../../js/base.js"></script>
        <script src="../../js/MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
        <script src="../../js/mymathjax.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">关闭</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">搜索</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            请在下面输入你要搜索的文本（仅支持英文）：
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="搜索..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>