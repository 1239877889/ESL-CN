<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://szcf-weiya.github.io/ESL-CN/05 Basis Expansions and Regularization/5.2 Piecewise Polynomials and Splines/">
        <link rel="shortcut icon" href="../../img/favicon.ico">

	<title>5.2 分段多项式和样条 - ESL CN</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/newsprint.css" rel="stylesheet">
        <link href="../../css/admonition_fix.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-85046550-1', 'auto');
          ga('send', 'pageview');

        </script>
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="../..">ESL CN</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
                <li >
                    <a href="../..">主页</a>
                </li>
            
            
            
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">目录 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">序言</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../Preface/2016-07-20-Preface-to-the-Second-Edition/">第二版序言</a>
</li>

        
            
<li >
    <a href="../../Preface/2016-07-21-Preface-to-the-First-Edition/">第一版序言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">1 简介</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../01 Introduction/2016-07-26-Chapter-1-Introduction/">1.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">2 监督学习概要</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.1 Introduction/">2.1 导言</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.2 Variable Types and Terminology/">2.2 变量类型和术语</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.3 Two Simple Approaches to Prediction/">2.3 两种预测的简单方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.4 Statistical Decision Theory/">2.4 统计判别理论</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.5 Local Methods in High Dimensions/">2.5 高维问题的局部方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.6 Statistical Models, Supervised Learning and Function Approximation/">2.6 统计模型，监督学习和函数逼近</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.7 Structured Regression Models/">2.7 结构化的回归模型</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.8 Classes of Restricted Estimators/">2.8 限制性估计的类别</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.9 Model Selection and the Bias-Variance Tradeoff/">2.9 模型选择和偏差-方差的权衡</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">3 回归的线性方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.1 Introduction/">3.1 导言</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.2 Linear Regression Models and Least Squares/">3.2 线性回归模型和最小二乘法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.3 Subset Selection/">3.3 子集的选择</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.4 Shrinkage Methods/">3.4 收缩的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.5 Methods Using Derived Input Directions/">3.5 运用派生输入方向的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.6 A Comparison of the Selection and Shrinkage Methods/">3.6 选择和收缩方法的比较</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.7 Multiple Outcome Shrinkage and Selection/">3.7 多重输出的收缩和选择</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">4 分类的线性方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.1 Introduction/">4.1 导言</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.2 Linear Regression of an Indicator Matrix/">4.2 指示矩阵的线性回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.3 Linear Discriminant Analysis/">4.3 线性判别分析</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.4 Logistic Regression/">4.4 逻辑斯蒂回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.5 Separating Hyperplanes/">4.5 分离超平面</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">5 基展开和正规化</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../5.1 Introduction/">5.1 导言</a>
</li>

        
            
<li class="active">
    <a href="./">5.2 分段多项式和样条</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">6 核光滑方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.1 Introduction/">6.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">7 模型评估及选择</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.1 Introduction/">7.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">8 模型推断和平均</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.1 Introduction/">8.1 导言</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.2 The Bootstrap and Maximum Likelihood Methods/">8.2 自助法和最大似然法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.3 Bayesian Methods/">8.3 贝叶斯方法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.4 Relationship Between the Bootstrap and Bayesian Inference/">8.4 自助法和贝叶斯推断之间的关系</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.5 The EM Algorithm/">8.5 EM算法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.6 MCMC for Sampling from the Posterior/">8.6 MCMC向后采样</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.7 Bagging/">8.7 袋装法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">9 增广模型，树，以及相关方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.0 Introduction/">9.0 导言</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.1 Generalized Additive Models/">9.1 广义加性模型</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.2 Tree-Based Methods/">9.2 基于树的方法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">10 增强和加性树</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.1 Boosting Methods/">10.1 增强方法</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.2 Boosting Fits an Additive Model/">10.2 对加性模型的增强拟合</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.3 Forward Stagewise Additive Modeling/">10.3 向前逐步加性建模</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.4 Exponential Loss and AdaBoost/">10.4 指数损失和AdaBoost</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.5 Why Exponential Loss/">10.5 为什么是指数损失</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.6 Loss Functions and Robustness/">10.6 损失函数和鲁棒性</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">11 神经网络</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../11 Neural Networks/11.1 Introduction/">11.1 导言</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.2 Projection Pursuit Regression/">11.2 投影寻踪回归</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.3 Neural Networks/">11.3 神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.4 Fitting Neural Networks/">11.4 拟合神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.5 Some Issues in Training Neural Networks/">11.5 训练神经网络的一些问题</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.6 Example of Simulated Data/">11.6 模拟数据的例子</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">12 支持向量机和灵活的判别方法</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.1 Introduction/">12.1 导言</a>
</li>

        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.2 The Support Vector Classifier/">12.2 支持向量分类器</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">13 原型方法和最近邻</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.1 Introduction/">13.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">15 随机森林</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../15 Random Forests/15.1 Introduction/">15.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                    </ul>
                </li>
            
            
            </ul>

            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> 搜索
                    </a>
                </li>
                <li >
                    <a rel="next" href="../5.1 Introduction/">
                        <i class="fa fa-arrow-left"></i> 上一节
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../../06 Kernel Smoothing Methods/6.1 Introduction/">
                        下一节 <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                <li>
                    <a href="https://szcf-weiya.github.io">
                        
                        Szcf-Weiya
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#_1">分段多项式和样条</a></li>
        
            <li><a href="#_2">自然三次样条</a></li>
        
            <li><a href="#_3">例子：南非心脏病（继续）</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="_1">分段多项式和样条</h1>
<table>
<thead>
<tr>
<th>原文</th>
<th><a href="../../book/The Elements of Statistical Learning.pdf">The Elements of Statistical Learning</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>翻译</td>
<td>szcf-weiya</td>
</tr>
<tr>
<td>时间</td>
<td>2017-02-08</td>
</tr>
</tbody>
</table>
<p>直到5.7节我们都假设$X$为一维向量。分段多项式函数$f(X)$通过将$X$的定义域分成连续的区间，然后在每个区间内用单独的多项式来表示$f$。图5.1显示了两个简单的分段多项式。第一个是分段常值，含有三个基函数：
<script type="math/tex; mode=display">
h_1(X)=I(X<\xi_1),\;h_2(X)=I(\xi_1\le X\le \xi_2),\;h_3(X)=I(\xi_2\le X)
</script>
因为这些在不连续区域为正值，模型$f(X)=\sum_{m=1}^3\beta_mh_m(X)$等价于$\hat\beta_m=\overline{Y}_m$,即为$Y$在第$m$个区域的均值。</p>
<p><img alt="" src="../../img/05/fig5.1.png" /></p>
<blockquote>
<p>图5.1. 上面图显示了对一些人造数据的分段常值函数拟合。垂直虚线表示两个结点$\xi_1$和$\xi_2$.蓝色曲线表示真正的函数，数据是通过函数加上高斯噪声产生的。下面板的图显示了对同样数据的分段线性函数拟合——上面板的图没有限制，而下面板的图限制为在结点处连续——右上图没有限制，而左下图限制为在结点处连续。右下图显示了分段线性的基函数，$h_3(X)=(X-\xi_1)_+$,它在$\xi_1$处连续。黑色点表示样本取值$h_3(x_i),i=1,2,\ldots,N$</p>
</blockquote>
<p>右上图显示了分段线性拟合。需要三个额外的基函数：$h_{m+3}=h_m(X)X,m=1,2,3$.除了特殊的情形，我们一般更想要第三个面板的图，也是分段线性，但在间隔点上连续。这些连续性的约束导致在参数上的线性约束；举个例子，$f(\xi_1^-)=f(\xi_1^+)$意味着$\beta_1+\xi_1\beta_4=\beta_2+\xi_1\beta_5$.在这种情形下，因为存在两个约束，我们期望得到两个参数，而抛弃4个自由参数。</p>
<p>这种情形下更直接的方式是将约束结合起来的基函数：
<script type="math/tex; mode=display">
h_1(X)=1,\;h_2(X)=X,\;h_3(X)=(X-\xi_1)_+,\;h_4(X)=(X-\xi_2)_+
</script>
其中$t_+$记为正的部分。函数$h_3$的图象如图5.1显示。我们经常偏好光滑函数，这个可以通过增加局部多项式的阶数实现。图5.2显示了一系列对同样数据进行的分段3次多项式拟合，增加了结点处的连续性的阶数。右下图的函数是连续的，且在结点处的一阶微分和二阶微分均连续。这称为三次样条。再加一阶的连续性可以导致全局三次多项式。不难证明（练习5.1）下面的基函数表示结点为$\xi_1$和$\xi_2$的三次样条。
<script type="math/tex; mode=display">
\begin{align}
h_1(X)=1,\;h_3(X)=X^2,\;&h_5(X)=(X-\xi_1)_+^3\\
h_2(X)=X,\;h_4(X)=X^3,\;&h_6(X)=(X-\xi_2)_+^3
\end{align}
\qquad (5.3)
</script>
这里6个基函数对应6维函数的线性空间。快速地确定参数个数：（3个区域）$\times$ (每个区域4个参数)-（2个结点）$\times$（每个结点3个限制）=6.</p>
<p><img alt="" src="../../img/05/fig5.2.png" /></p>
<blockquote>
<p>图5.2. 一系列分段3次多项式拟合，增加了连续性的阶数。</p>
</blockquote>
<p>更一般地，结点为$\xi_j,j=1,\ldots,K$的阶数为$M$的样条是阶数为$M$的分段多项式，而且有连续的$M-2$阶微分。三次样条的$M=4$。实际上图5.1的分段常数函数是阶数为1的样条，而连续的分段线性函数是阶数为2的样条。同样地，截断（truncated-power）基的集合是
<script type="math/tex; mode=display">
\begin{align}
h_j(X)&=X^{j-1},j=1,\ldots,M\\
h_{M+\ell}(X)&=(X-\xi_\ell)_+^{M-1},\ell=1,\ldots,K
\end{align}
</script>
</p>
<p>声称三次样条是使得人眼看不出结点不连续的最低阶样条。需要选择样条的阶数，结点的个数以及它们的位置。参量化样条族的一种简单方式是通过基函数或者自由度，而且用观测$x_i$来确定结点的位置。举个例子，R语言中的表达式bs(x,df=7)产生在x中$N$个观测点取值的三次样条基函数，其中有$7-3=4$个内结点，内结点在x的（20,40,60和80）分位数处。（含四个结点的三次样条是8个维度的。bs()函数默认忽略基函数里面的常数项，因为这样的项一般包含在模型的其它项里面。）然而，也可以更明确地指出，bs(x, degree=1, knots=c(0.2,0.4,0.6))产生有三个内结点的线性样条的基，并且返回一个$N\times 4$的矩阵。</p>
<p>因为特定阶数以及结点序列的样条函数的空间是向量空间，所以表示它们有许多等价的基底（就像普通多项式一样。）尽管truncated power基在概念上很简单，但是数值计算时不是很吸引人：大的数值的power可以导致非常严重的舍入问题。在本章附录中描述的B样条的基即使在结点数$K$很大时也有很高的计算效率。</p>
<h2 id="_2">自然三次样条</h2>
<p>我们知道对数据的多项式拟合的行为在边界处有不稳定的趋势，而且外推法可以很危险。这些问题被样条进一步恶化。边界结点之外的多项式拟合的表现比该区域对应的全局多项式拟合更野蛮。这个可以通过最小二乘拟合的样条函数的逐点方差方便地总结出来（更多细节见下一节的计算这些方差的例子）。图5.3比较了不同模型的逐点方差。在边界处的方差爆炸是显而易见的，对于三次样条这必要会更糟糕。</p>
<p>自然三次样条添加额外的限制，换句话说在边界结点之外的线性函数。这样减少了4个自由度（两个边界区域分别两个限制条件），这四个自由度可以通过在内部区域取更多的结点花费掉。图5.3用方差表示了这种权衡。在边界附近需要在偏差上付出代价，但是假设边界附近（不管怎样，我们的信息很少）为线性函数通常是合理的考虑。</p>
<p>含$K$个结点的自然三次样条用$K$基函数来表示。可以从三次样条的出发，通过强加上边界限制导出降维的基。举个例子，从5.2节描述的truncated power序列基出发，我们得到（练习5.4）：
<script type="math/tex; mode=display">
N_1(X)=1,\;N_2(X)=X,\; N_{k+2}(X)=d_k(X)-d_{K-1}(X),\qquad (5.4)
</script>
其中，
<script type="math/tex; mode=display">
d_k(X)=\frac{(X-\xi_k)_+^3-(X-\xi_K)_+^3}{\xi_K-\xi_k}\qquad (5.5)
</script>
可以看到当$X\ge \xi_K$时每个基函数的二阶微分和三阶微分均为0.</p>
<h2 id="_3">例子：南非心脏病（继续）</h2>
<p>在4.4.2节我们对南非心脏病数据进行了线性逻辑斯蒂回归拟合。这里我们以采用自然样条的函数来探索非线性。模型的函数有如下形式：
<script type="math/tex; mode=display">
\mathrm{logit}[Pr(chd\mid X)]=\theta_0+h_1(X_1)^T\theta_1+h_2(X_2)^T\theta_2+\cdots+h_p(X_p)^T\theta_p\qquad (5.6)
</script>
其中每个$\theta_i$都是乘以对应自然样条基函数$h_j$的系数向量。</p>
<p>我们在模型中对每一项采用4个自然样条基。举个例子，$X_1$代表sbp，$h_1(X_1)$是包含四个基函数的基。这实际上表明有三个而非两个内结点（在sbp的均匀分位数结点处取值），加上在数据端点的两个边界结点，因为我们把$h_j$的常数项提取出来了。</p>
<blockquote>
<p>weiya注：</p>
<p>因为把常数项单独提出来，所以原本应该为5个基函数。对于自然三次样条来说，$K$个基函数表示含有$K$个结点。</p>
<p>因为三次样条$M=4$，$K$为结点个数（含边界点）</p>
<p>$M+K=4+$基函数个数</p>
<p>则$K$个基函数表示含有$K$个结点。</p>
<p>这里，总共5个结点，除去边界点，则还剩3个内结点。</p>
</blockquote>

<div id="disqus_thread"></div>
<script>

/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
/*
var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//weiya.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<script id="dsq-count-scr" src="//weiya.disqus.com/count.js" async></script></div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <center>Powered by <a href="http://www.mkdocs.org/">MkDocs</a> and <a href="http://bootswatch.com/yeti/">Yeti</a></center>
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>var base_url = '../..';</script>
        <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
        <script src="../../js/base.js"></script>
        <script src="../../js/MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
        <script src="../../js/mymathjax.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">关闭</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">搜索</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            请在下面输入你要搜索的文本（仅支持英文）：
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="搜索..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>