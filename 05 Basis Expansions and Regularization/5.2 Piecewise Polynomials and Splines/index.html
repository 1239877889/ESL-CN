<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="The Elements of Statistical Learning(ESL) 的中文笔记">
        
        <link rel="canonical" href="https://szcf-weiya.github.io/ESL-CN/05 Basis Expansions and Regularization/5.2 Piecewise Polynomials and Splines/">
	<link rel="shortcut icon" href="../../img/favicon.ico">

	<title>5.2 分段多项式和样条 - ESL CN</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/newsprint.css" rel="stylesheet">
        <link href="../../css/admonition_fix.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-85046550-1', 'auto');
          ga('send', 'pageview');

        </script>
        <!--mathjax-->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          tex2jax: {
          	inlineMath: [['$','$'], ['\\(','\\)']],
          	processEscapes:true
          },
          TeX: {
          	entensions: ["color.js"]
          }
          });
        </script>
        <script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2-beta.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
<!--
	<style>
	  .dropdown-menu {
    max-height: 500px;
    overflow-y: auto;
    overflow-x: auto;
}
	</style>
-->
    </head>
    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="">ESL CN</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
                <li >
                    <a href="../..">主页</a>
                </li>
            
            
            
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">上篇 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">序言</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../Preface/2016-07-20-Preface-to-the-Second-Edition/">第二版序言</a>
</li>

        
            
<li >
    <a href="../../Preface/2016-07-21-Preface-to-the-First-Edition/">第一版序言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">1 简介</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../01 Introduction/2016-07-26-Chapter-1-Introduction/">1.1 导言</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">2 监督学习概要</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.1 Introduction/">2.1 导言</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.2 Variable Types and Terminology/">2.2 变量类型和术语</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.3 Two Simple Approaches to Prediction/">2.3 两种预测的简单方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.4 Statistical Decision Theory/">2.4 统计判别理论</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.5 Local Methods in High Dimensions/">2.5 高维问题的局部方法</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.6 Statistical Models, Supervised Learning and Function Approximation/">2.6 统计模型，监督学习和函数逼近</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.7 Structured Regression Models/">2.7 结构化的回归模型</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.8 Classes of Restricted Estimators/">2.8 限制性估计的类别</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/2.9 Model Selection and the Bias-Variance Tradeoff/">2.9 模型选择和偏差-方差的权衡</a>
</li>

        
            
<li >
    <a href="../../02 Overview of Supervised Learning/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">3 回归的线性方法</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.1 Introduction/">3.1 导言</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.2 Linear Regression Models and Least Squares/">3.2 线性回归模型和最小二乘法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.3 Subset Selection/">3.3 子集的选择</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.4 Shrinkage Methods/">3.4 收缩的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.5 Methods Using Derived Input Directions/">3.5 运用派生输入方向的方法</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.6 A Comparison of the Selection and Shrinkage Methods/">3.6 选择和收缩方法的比较</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.7 Multiple Outcome Shrinkage and Selection/">3.7 多重输出的收缩和选择</a>
</li>

        
            
<li >
    <a href="../../03 Linear Methods for Regression/3.8 More on the Lasso and Related Path Algorithms/">3.8 Lasso和相关路径算法的补充</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">4 分类的线性方法</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.1 Introduction/">4.1 导言</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.2 Linear Regression of an Indicator Matrix/">4.2 指示矩阵的线性回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.3 Linear Discriminant Analysis/">4.3 线性判别分析</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.4 Logistic Regression/">4.4 逻辑斯蒂回归</a>
</li>

        
            
<li >
    <a href="../../04 Linear Methods for Classification/4.5 Separating Hyperplanes/">4.5 分离超平面</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">5 基展开和正规化</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../5.1 Introduction/">5.1 导言</a>
</li>

        
            
<li class="active">
    <a href="./">5.2 分段多项式和样条</a>
</li>

        
            
<li >
    <a href="../5.3 Filtering and Feature Extraction/">5.3 滤波和特征提取</a>
</li>

        
            
<li >
    <a href="../5.4 Smoothing Splines/">5.4 光滑样条</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">6 核光滑方法</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.0 Introduction/">6.0 导言</a>
</li>

        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.1 One-Dimensional Kernel Smoothers/">6.1 一维核光滑器</a>
</li>

        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.2 Selecting the Width of the Kernel/">6.2 选择核的宽度</a>
</li>

        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.3 Local Regression in R^p/">6.3 $R^p$中的局部回归</a>
</li>

        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.4 Structured Local Regression Models in R^p/">6.4 $R^p$中的结构化局部回归模型</a>
</li>

        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.5 Local Likelihood and Other Models/">6.5 局部似然和其他模型</a>
</li>

        
            
<li >
    <a href="../../06 Kernel Smoothing Methods/6.6 Kernel Density Estimation and Classification/">6.6 核密度估计和分类</a>
</li>

        
    </ul>
  </li>

                    
                    </ul>
                </li>
            
            
            
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">中篇 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">7 模型评估及选择</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.1 Introduction/">7.1 导言</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.2 Bias, Variance and Model Complexity/">7.2 偏差，方差和模型复杂度</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.3 The Bias-Variance Decomposition/">7.3 偏差-方差分解</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.4 Optimism of the Training Error Rate/">7.4 测试误差率的乐观</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.5 Estimates of In-Sample Prediction Error/">7.5 样本内预测误差的估计</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.6 The Effective Number of Parameters/">7.6 参数的有效个数</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.7 The Bayesian Approach and BIC/">7.7 贝叶斯方法和BIC</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.8 Minimum Description Length/">7.8 最小描述长度</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.9 Vapnik-Chervonenkis Dimension/">7.9 VC维</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.10 Cross-Validation/">7.10 交叉验证</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.11 Bootstrap Methods/">7.11 自助法</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/7.12 Conditional or Expected Test Error/">7.12 条件测试误差或期望测试误差</a>
</li>

        
            
<li >
    <a href="../../07 Model Assessment and Selection/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">8 模型推断和平均</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.1 Introduction/">8.1 导言</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.2 The Bootstrap and Maximum Likelihood Methods/">8.2 自助法和最大似然法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.3 Bayesian Methods/">8.3 贝叶斯方法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.4 Relationship Between the Bootstrap and Bayesian Inference/">8.4 自助法和贝叶斯推断之间的关系</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.5 The EM Algorithm/">8.5 EM算法</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.6 MCMC for Sampling from the Posterior/">8.6 MCMC向后采样</a>
</li>

        
            
<li >
    <a href="../../08 Model Inference and Averaging/8.7 Bagging/">8.7 袋装法</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">9 增广模型，树，以及相关方法</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.0 Introduction/">9.0 导言</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.1 Generalized Additive Models/">9.1 广义加性模型</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.2 Tree-Based Methods(CART)/">9.2 基于树的方法</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.3 PRIM(Bump Hunting)/">9.3 耐心规则归纳法</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.4 MARS(Multivariate Adaptive Regression Splines)/">9.4 多变量自适应回归样条</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.5 Hierarchical Mixtures of Experts/">9.5 专家的系统混合</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.6 Missing Data/">9.6 缺失数据</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/9.7 Computational Considerations/">9.7 计算上的考虑</a>
</li>

        
            
<li >
    <a href="../../09 Additive Models, Trees, and Related Methods/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">10 增强和加性树</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.1 Boosting Methods/">10.1 增强方法</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.2 Boosting Fits an Additive Model/">10.2 boosting拟合可加模型</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.3 Forward Stagewise Additive Modeling/">10.3 向前逐步加性建模</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.4 Exponential Loss and AdaBoost/">10.4 指数损失和AdaBoost</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.5 Why Exponential Loss/">10.5 为什么是指数损失</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.6 Loss Functions and Robustness/">10.6 损失函数和鲁棒性</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.7 Off-the-Shelf Procedures for Data Mining/">10.7 数据挖掘的现货方法</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.8 Spam Data/">10.8 垃圾邮件的例子</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.9 Boosting Trees/">10.9 boosting树</a>
</li>

        
            
<li >
    <a href="../../10 Boosting and Additive Trees/10.10 Numerical Optimization via Gradient Boosting/">10.10 利用梯度boosting的数值优化</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">11 神经网络</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../11 Neural Networks/11.1 Introduction/">11.1 导言</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.2 Projection Pursuit Regression/">11.2 投影寻踪回归</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.3 Neural Networks/">11.3 神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.4 Fitting Neural Networks/">11.4 拟合神经网络</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.5 Some Issues in Training Neural Networks/">11.5 训练神经网络的一些问题</a>
</li>

        
            
<li >
    <a href="../../11 Neural Networks/11.6 Example of Simulated Data/">11.6 模拟数据的例子</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">12 支持向量机和灵活的判别方法</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.1 Introduction/">12.1 导言</a>
</li>

        
            
<li >
    <a href="../../12 Support Vector Machines and Flexible Discriminants/12.2 The Support Vector Classifier/">12.2 支持向量分类器</a>
</li>

        
    </ul>
  </li>

                    
                    </ul>
                </li>
            
            
            
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">下篇 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">13 原型方法和最近邻</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.1 Introduction/">13.1 导言</a>
</li>

        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.2 Prototype Methods/">13.2 原型方法</a>
</li>

        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.3 k-Nearest-Neighbor Classifiers/">13.3 k最近邻分类器</a>
</li>

        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.4 Adaptive Nearest-Neighbor Methods/">13.4 自适应的最近邻方法</a>
</li>

        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/13.5 Computational Considerations/">13.5 计算上的考虑</a>
</li>

        
            
<li >
    <a href="../../13 Prototype Methods and Nearest-Neighbors/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">14 非监督学习</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../14 Unsupervised Learning/14.1 Introduction/">14.1 导言</a>
</li>

        
            
<li >
    <a href="../../14 Unsupervised Learning/14.2 Association Rules/">14.2 关联规则</a>
</li>

        
            
<li >
    <a href="../../14 Unsupervised Learning/14.3 Cluster Analysis/">14.3 聚类分析</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">15 随机森林</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../15 Random Forests/15.1 Introduction/">15.1 导言</a>
</li>

        
            
<li >
    <a href="../../15 Random Forests/15.2 Definition of Random Forests/">15.2 随机森林的定义</a>
</li>

        
            
<li >
    <a href="../../15 Random Forests/15.3 Details of Random Forests/">15.3 随机森林的细节</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">16 增强学习</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../16 Ensemble Learning/16.1 Introduction/">16.1 导言</a>
</li>

        
            
<li >
    <a href="../../16 Ensemble Learning/16.2 Boosting and Regularization Paths/">16.2 增强和正则路径</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">17 无向图模型</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../17 Undirected Graphical Models/17.1 Introduction/">17.1 导言</a>
</li>

        
            
<li >
    <a href="../../17 Undirected Graphical Models/17.2 Markov Graphs and Their Properties/">17.2 马尔科夫图及其性质</a>
</li>

        
            
<li >
    <a href="../../17 Undirected Graphical Models/17.3 Undirected Graphical Models for Continuous Variables/">17.3 连续变量的无向图模型</a>
</li>

        
            
<li >
    <a href="../../17 Undirected Graphical Models/17.4 Undirected Graphical Models for Discrete Variables/">17.4 离散变量的无向图模型</a>
</li>

        
            
<li >
    <a href="../../17 Undirected Graphical Models/Bibliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu scrollable-menu">
    <a tabindex="-1" class="nav-title">18 高维问题</a>
    <ul class="dropdown-menu scrollable-menu">
        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.1 When p is Much Bigger than N/">18.1 当p大于N</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.2 Diagonal Linear Discriminant Analysis and Nearest Shrunken Centroids/">18.2 对角线性判别分析和最近收缩重心</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.3 Linear Classifiers with Quadratic Regularization/">18.3 二次正则的线性分类器</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.4 Linear Classifiers with L1 Regularization/">18.4 一次正则的线性分类器</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.5 Classification When Features are Unavailable/">18.5 当特征不可用时的分类</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.6 High-Dimensional Regression/">18.6 有监督的主成分</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/18.7 Feature Assessment and the Multiple-Testing Problem/">18.7 特征评估和多重检验问题</a>
</li>

        
            
<li >
    <a href="../../18 High-Dimensional Problems/Bioliographic Notes/">文献笔记</a>
</li>

        
    </ul>
  </li>

                    
                    </ul>
                </li>
            
            
            </ul>

            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
              <!--
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> 搜索
                    </a>
                </li>
              -->
                <li>
                  <a href="https://szcf-weiya.github.io/ESL-CN/05 Basis Expansions and Regularization/5.2 Piecewise Polynomials and Splines/#disqus_thread">0 Comments</a>
                </li>
                <li >
                    <a rel="next" href="../5.1 Introduction/">
                        <i class="fa fa-arrow-left"></i> 上一节
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../5.3 Filtering and Feature Extraction/">
                        下一节 <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                <li>
                    <a href="https://szcf-weiya.github.io">
                        
                        Szcf-Weiya
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#_1">分段多项式和样条</a></li>
        
            <li><a href="#_2">自然三次样条</a></li>
        
            <li><a href="#_3">例子：南非心脏病（继续）</a></li>
        
            <li><a href="#_4">例子：音素识别</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="_1">分段多项式和样条</h1>
<table>
<thead>
<tr>
<th>原文</th>
<th><a href="../../book/The Elements of Statistical Learning.pdf">The Elements of Statistical Learning</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>翻译</td>
<td>szcf-weiya</td>
</tr>
<tr>
<td>时间</td>
<td>2017-02-08:2017-02-16</td>
</tr>
</tbody>
</table>
<p>直到5.7节我们都假设$X$为一维向量。分段多项式函数$f(X)$通过将$X$的定义域分成连续的区间，然后在每个区间内用单独的多项式来表示$f$。图5.1显示了两个简单的分段多项式。第一个是分段常值，含有三个基函数：
<script type="math/tex; mode=display">
h_1(X)=I(X<\xi_1),\;h_2(X)=I(\xi_1\le X\le \xi_2),\;h_3(X)=I(\xi_2\le X)
</script>
因为这些在不连续区域为正值，模型$f(X)=\sum_{m=1}^3\beta_mh_m(X)$等价于$\hat\beta_m=\overline{Y}_m$,即为$Y$在第$m$个区域的均值。</p>
<p><img alt="" src="../../img/05/fig5.1.png" /></p>
<blockquote>
<p>图5.1. 上面图显示了对一些人造数据的分段常值函数拟合。垂直虚线表示两个结点$\xi_1$和$\xi_2$.蓝色曲线表示真正的函数，数据是通过函数加上高斯噪声产生的。下面板的图显示了对同样数据的分段线性函数拟合——上面板的图没有限制，而下面板的图限制为在结点处连续——右上图没有限制，而左下图限制为在结点处连续。右下图显示了分段线性的基函数，$h_3(X)=(X-\xi_1)_+$,它在$\xi_1$处连续。黑色点表示样本取值$h_3(x_i),i=1,2,\ldots,N$</p>
</blockquote>
<p>右上图显示了分段线性拟合。需要三个额外的基函数：$h_{m+3}=h_m(X)X,m=1,2,3$.除了特殊的情形，我们一般更想要第三个面板的图，也是分段线性，但在间隔点上连续。这些连续性的约束导致在参数上的线性约束；举个例子，$f(\xi_1^-)=f(\xi_1^+)$意味着$\beta_1+\xi_1\beta_4=\beta_2+\xi_1\beta_5$.在这种情形下，因为存在两个约束，我们期减少了两个参数，最终得到4个自由参数。</p>
<p>这种情形下更直接的方式是将约束结合起来的基函数：
<script type="math/tex; mode=display">
h_1(X)=1,\;h_2(X)=X,\;h_3(X)=(X-\xi_1)_+,\;h_4(X)=(X-\xi_2)_+
</script>
其中$t_+$记为正的部分。函数$h_3$的图象如图5.1显示。我们经常偏好光滑函数，这个可以通过增加局部多项式的阶数实现。图5.2显示了一系列对同样数据进行的分段3次多项式拟合，增加了结点处的连续性的阶数。右下图的函数是连续的，且在结点处的一阶微分和二阶微分均连续。这称为三次样条。再加一阶的连续性可以导致全局三次多项式。不难证明（练习5.1）下面的基函数表示结点为$\xi_1$和$\xi_2$的三次样条。
<script type="math/tex; mode=display">
\begin{align}
h_1(X)=1,\;h_3(X)=X^2,\;&h_5(X)=(X-\xi_1)_+^3\\
h_2(X)=X,\;h_4(X)=X^3,\;&h_6(X)=(X-\xi_2)_+^3
\end{align}
\qquad (5.3)
</script>
这里6个基函数对应6维函数的线性空间。快速地确定参数个数：（3个区域）$\times$ (每个区域4个参数)-（2个结点）$\times$（每个结点3个限制）=6.</p>
<p><img alt="" src="../../img/05/fig5.2.png" /></p>
<blockquote>
<p>图5.2. 一系列分段3次多项式拟合，增加了连续性的阶数。</p>
</blockquote>
<p>更一般地，结点为$\xi_j,j=1,\ldots,K$的阶数为$M$的样条是阶数为$M$的分段多项式，而且有连续的$M-2$阶微分。三次样条的$M=4$。实际上图5.1的分段常数函数是阶数为1的样条，而连续的分段线性函数是阶数为2的样条。同样地，截断（truncated-power）基的集合是
<script type="math/tex; mode=display">
\begin{align}
h_j(X)&=X^{j-1},j=1,\ldots,M\\
h_{M+\ell}(X)&=(X-\xi_\ell)_+^{M-1},\ell=1,\ldots,K
\end{align}
</script>
</p>
<p>声称三次样条是使得人眼看不出结点不连续的最低阶样条。需要选择样条的阶数，结点的个数以及它们的位置。参量化样条族的一种简单方式是通过基函数或者自由度，而且用观测$x_i$来确定结点的位置。举个例子，R语言中的表达式bs(x,df=7)产生在x中$N$个观测点取值的三次样条基函数，其中有$7-3=4$个内结点，内结点在x的（20,40,60和80）分位数处。（含四个结点的三次样条是8个维度的。bs()函数默认忽略基函数里面的常数项，因为这样的项一般包含在模型的其它项里面。）然而，也可以更明确地指出，bs(x, degree=1, knots=c(0.2,0.4,0.6))产生有三个内结点的线性样条的基，并且返回一个$N\times 4$的矩阵。</p>
<p>因为特定阶数以及结点序列的样条函数的空间是向量空间，所以表示它们有许多等价的基底（就像普通多项式一样。）尽管truncated power基在概念上很简单，但是数值计算时不是很吸引人：大的数值的power可以导致非常严重的舍入问题。在本章附录中描述的B样条的基即使在结点数$K$很大时也有很高的计算效率。</p>
<h2 id="_2">自然三次样条</h2>
<p>我们知道对数据的多项式拟合的行为在边界处有不稳定的趋势，而且外推法可以很危险。这些问题被样条进一步恶化。边界结点之外的多项式拟合的表现比该区域对应的全局多项式拟合更野蛮。这个可以通过最小二乘拟合的样条函数的逐点方差方便地总结出来（更多细节见下一节的计算这些方差的例子）。图5.3比较了不同模型的逐点方差。在边界处的方差爆炸是显而易见的，对于三次样条这必要会更糟糕。</p>
<p>自然三次样条添加额外的限制，换句话说在边界结点之外的线性函数。这样减少了4个自由度（两个边界区域分别两个限制条件），这四个自由度可以通过在内部区域取更多的结点花费掉。图5.3用方差表示了这种权衡。在边界附近需要在偏差上付出代价，但是假设边界附近（不管怎样，我们的信息很少）为线性函数通常是合理的考虑。</p>
<p>含$K$个结点的自然三次样条用$K$基函数来表示。可以从三次样条的出发，通过强加上边界限制导出降维的基。举个例子，从5.2节描述的truncated power序列基出发，我们得到（练习5.4）：
<script type="math/tex; mode=display">
N_1(X)=1,\;N_2(X)=X,\; N_{k+2}(X)=d_k(X)-d_{K-1}(X),\qquad (5.4)
</script>
其中，
<script type="math/tex; mode=display">
d_k(X)=\frac{(X-\xi_k)_+^3-(X-\xi_K)_+^3}{\xi_K-\xi_k}\qquad (5.5)
</script>
可以看到当$X\ge \xi_K$时每个基函数的二阶微分和三阶微分均为0.</p>
<h2 id="_3">例子：南非心脏病（继续）</h2>
<p>在4.4.2节我们对南非心脏病数据进行了线性逻辑斯蒂回归拟合。这里我们以采用自然样条的函数来探索非线性。模型的函数有如下形式：
<script type="math/tex; mode=display">
\mathrm{logit}[Pr(chd\mid X)]=\theta_0+h_1(X_1)^T\theta_1+h_2(X_2)^T\theta_2+\cdots+h_p(X_p)^T\theta_p\qquad (5.6)
</script>
其中每个$\theta_i$都是乘以对应自然样条基函数$h_j$的系数向量。</p>
<p>我们在模型中对每一项采用4个自然样条基。举个例子，$X_1$代表sbp，$h_1(X_1)$是包含四个基函数的基。这实际上表明有三个而非两个内结点（在sbp的均匀分位数结点处取值），另外在数据端点有两个边界结点，因为我们把$h_j$的常数项提取出来了。</p>
<blockquote>
<p>weiya注：</p>
<p>因为把常数项单独提出来，所以原本应该为5个基函数。对于自然三次样条来说，$K$个基函数表示含有$K$个结点。</p>
<p>因为三次样条$M=4$，$K$为结点个数（含边界点）</p>
<p>$M+K=4+$基函数个数</p>
<p>则$K$个基函数表示含有$K$个结点。</p>
<p>这里，总共5个结点，除去边界点，则还剩3个内结点。</p>
</blockquote>
<div class="admonition note">
<p class="admonition-title">weiya注：</p>
<p>因为把常数项单独提出来，所以原本应该为5个基函数。对于自然三次样条来说，$K$个基函数表示含有$K$个结点。</p>
<p>因为三次样条$M=4$，$K$为结点个数（含边界点）</p>
<p>$M+K=4+$基函数个数</p>
<p>则$K$个基函数表示含有$K$个结点。</p>
<p>这里，总共5个结点，除去边界点，则还剩3个内结点。</p>
</div>
<p>因为famhist是含两个水平的因子，所以通过一个二进制变量或者虚拟变量来编码，而且它与模型拟合中的单系数有关。</p>
<p>更简洁地，我们将$p$维基函数（以及常数项）向量结合成一个向量$h(X)$，则模型简化为$h(X)^T\theta$，总参数个数为$df=1+\sum_{j=1}^pdf_j$，是每个组分中参数个数的和。每个基函数在$N$个样本中分别取值，得到一个$N\times df$的基矩阵$\mathbf H$.在这点上看，模型类似于其他的线性逻辑斯蒂回归模型，应用的算法在4.4.1节描述。</p>
<p>我们采用向后逐步删除过程，从模型中删除项并且保持每个项的群体结构，而不是每次删除一个系数。AIC统计量（7.5节）用来删除项，并且在最后模型中保留下来的所有项如果被删掉都会导致AIC增大（见表5.1）.图5.4显示了通过逐步回归选择出的最终模型的图象。对于每个变量$X_j$，画出的函数是$\hat f_j(X_j)=h_j(X_j)^T\hat\theta_j$。协方差矩阵$Cov(\hat\theta)=\mathbf\Sigma$通过$\mathbf{\hat\Sigma=(H^TWH)^{-1}}$来估计，其中$\mathbf W$为逻辑斯蒂回归的对角元素构成的权重矩阵。因此$v_j(X_j)=Var[\hat f_j(X_j)]=h_j(X_j)^T\mathbf{\hat \Sigma}<em>{jj}h_j(X_j)$是$\hat f_j$的逐点方差函数，其中$Cov(\hat\theta_j)=\hat{\mathbf\Sigma}</em>{jj}$是$\hat{\mathbf\Sigma}$对应的子矩阵。图5.4中每张图的阴影区域由$\hat f_j(X_j)\pm2\sqrt{v_j(X_j)}$定义。</p>
<p>AIC统计量比似然比检验（偏差检验）更“宽容”（generous）。sbp和obesity都被包含进模型中，而不在线性模型中。图象解释了为什么它们的贡献本质上非线性。这些影响乍看或许很惊讶，但解释在于回顾性数据的本质。这些指标有时是当病人患上心脏病后测出来的，而且在很多情形下他们已经受益于健康饮食和生活状态，因此在obesity和sbp值较低时会有明显的增长。表5.1显示了所选模型的摘要。</p>
<h2 id="_4">例子：音素识别</h2>
<p>在这个例子中我们采用样条来降低灵活性而非增大灵活性；这个应用在一般的函数型建模标题下。图5.5的上图显示了在256个频率下测量的两个音素“aa”和“ao”中的每一个的15个对数周期图的样本。目标是应用这些数据对口语音素进行分类。选择这两个音素是因为它们很难被分开。</p>
<p><img alt="" src="../../img/05/fig5.5.png" /></p>
<blockquote>
<p>图5.5 上图显示了对数周期图作为15个例子频率的函数，例子中每个音素“aa”和“ao”从总共695个“aa”和1022个“ao”中选取。每个对数周期图在256个均匀的空间频率处测量。下图显示了对数据进行极大似然拟合逻辑斯蒂回归得到的系数（作为频率的函数）的图象，将256个对数周期图值作为输入。系数被限制为在红色曲线中是光滑的，而在锯齿状灰色曲线中不受限制。</p>
</blockquote>
<div class="admonition note">
<p class="admonition-title">weiya注</p>
<p>周期图（Periodogram）：在信号处理中，周期图是信号谱密度的估计。</p>
</div>
<p>输入特征是长度为256的向量$x$，我们可以看成是在频率$f$的节点上取值的函数值$X(f)$向量。实际上，存在一个连续的类似信号，它是频率的函数，而且我们有它的一个取样版本。</p>
<p>图5.5的下面板图显示了对从695个“aa”和1022个“ao”选出的1000个训练样本进行极大似然拟合得到的线性逻辑斯蒂回归模型的系数。也作出了系数关于频率的函数图象，而且实际上我们可以根据下面的连续形式来思考模型</p>
<p>
<script type="math/tex; mode=display">
\mathrm{log}\frac{Pr(aa\mid X)}{Pr(ao\mid X)}=\int X(f)\beta(f)df\qquad (5.7)
</script>
</p>
<p>通过下式来近似</p>
<p>
<script type="math/tex; mode=display">
\sum\limits_{j=1}^{256}X(f_j)\beta(f_j)=\sum\limits_{j=1}^{256}x_j\beta_j\qquad (5.8)
</script>
</p>
<p>系数计算一个反函数，而且将会在时域内有可测的值，其中在两个类别中对数周期图不同。</p>
<p>灰色曲线十分粗糙。因为输入信号有相当强的正自相关性，这导致系数中的负自相关。另外，样本大小仅仅对于每个系数仅仅提供了4个有效的观测。</p>
<p>类似这样的应用运行自然的正则化。我们强制系数作为频率的函数均匀变化。图5.5中下图的红色曲线显示了对这些数据这样一个光滑参数曲线。我们看到低频率提供最有差别的力量。这个光滑不仅允许对相反的进行简单的解读，而且得到更加精确的分类器：</p>
<p><img alt="" src="../../img/05/tabno1.png" /></p>
<p>红色光滑曲线可以应用非常简单的自然三次样条得到。我们可以将系数函数表达成样条$\beta(f)=\sum_{m=1}^Mh_m(f)\theta_m$的展开。实际中这意味着$\beta=\mathbf H\theta$，其中，$\mathbf H$是 $p\times M$三次样条的基矩阵，定义在频率集上。这里我们采用$M=12$个基函数，其中结点均匀分布在表示频率的整数$1,2,\ldots,256$上。因为$x^T\beta=x^T\mathbf H\theta$，我们可以简单地将输入特征$x$替换成滤波（filtered）形式<script type="math/tex">x^*=\mathbf{H}^Tx</script>，并在$x^*$上通过线性逻辑斯蒂回归拟合$\theta$.红色曲线因此是$\beta(f)=h(f)^T\hat\theta$</p>

<div id="disqus_thread"></div>
<script>

/**
 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */

var disqus_config = function () {
    this.page.url = "https://szcf-weiya.github.io/ESL-CN/05 Basis Expansions and Regularization/5.2 Piecewise Polynomials and Splines/";  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = "https://szcf-weiya.github.io/ESL-CN/05 Basis Expansions and Regularization/5.2 Piecewise Polynomials and Splines/"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//weiya.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<script id="dsq-count-scr" src="//weiya.disqus.com/count.js" async></script></div>
        </div>

        <footer class="col-md-12">
            <hr>
            
                <center>Copyright &copy; 2016-2017 weiya</center>
            
            <center>Powered by <a href="http://www.mkdocs.org/">MkDocs</a> and <a href="http://bootswatch.com/yeti/">Yeti</a></center>
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>var base_url = '../..';</script>
        <script data-main="../../mkdocs/js/search.js" src="../../mkdocs/js/require.js"></script>
        <script src="../../js/base.js"></script>
	<script src="../../js/jquery.dropdown.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">关闭</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">搜索</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            请在下面输入你要搜索的文本（仅支持英文）：
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="搜索..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>